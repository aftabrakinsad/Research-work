# -*- coding: utf-8 -*-
"""Leaf Disease Detection Using Convolutional Neural Networks_A Proposed Model Using Tomato Plant Leaves.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t2iuafPD-_R1cUbkv2yuWudWEHV3rQZk
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf
import matplotlib as plt
import matplotlib.pyplot as plt
from PIL import Image
from IPython.display import HTML
from urllib.request import urlopen
from tensorflow.keras import models, layers
from sklearn.metrics import confusion_matrix
# %matplotlib inline

!unzip /content/drive/MyDrive/tomato_dataset3.zip

for dirname, _, filenames in os.walk('/content/tomato_dataset'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

BATCH_SIZE = 64
IMAGE_SIZE = 256
CHANNELS=3
EPOCHS=40

dataset = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/tomato_dataset",
    seed=123,
    shuffle=True,
    image_size=(IMAGE_SIZE,IMAGE_SIZE),
    batch_size=BATCH_SIZE
)

class_names = dataset.class_names
class_names

for image_batch, label_batch in dataset.take(1):
    print(image_batch.shape) # that batch has 32 images with 256*256 size and RGB
    print(label_batch.numpy()) # printing all the labels of those 32 images

    for image_batch, label_batch in dataset.take(1):
     print(image_batch[0].numpy())

plt.figure(figsize=(15, 10))
for image_batch, labels_batch in dataset.take(1):
    for i in range(15):
        ax = plt.subplot(5, 5, i + 1)
        plt.imshow(image_batch[i].numpy().astype("uint8"))
        plt.title(class_names[labels_batch[i]])
        plt.axis("off")

len(dataset)

train_size = 0.8
len(dataset)*train_size

train_ds = dataset.take(100)
len(train_ds)

test_ds = dataset.skip(100)
len(test_ds)

val_size=0.1
len(dataset)*val_size

val_ds = test_ds.take(12)
len(val_ds)

test_ds = test_ds.skip(12)
len(test_ds)

def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):
    assert (train_split + test_split + val_split) == 1

    ds_size = len(ds)

    if shuffle:
        ds = ds.shuffle(shuffle_size, seed=12)

    train_size = int(train_split * ds_size)
    val_size = int(val_split * ds_size)

    train_ds = ds.take(train_size)
    val_ds = ds.skip(train_size).take(val_size)
    test_ds = ds.skip(train_size).skip(val_size)

    return train_ds, val_ds, test_ds

train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)

len(train_ds)

len(val_ds)

len(test_ds)

train_ds = train_ds.cache().shuffle(2000).prefetch(buffer_size=tf.data.AUTOTUNE)
val_ds = val_ds.cache().shuffle(2000).prefetch(buffer_size=tf.data.AUTOTUNE)
test_ds = test_ds.cache().shuffle(2000).prefetch(buffer_size=tf.data.AUTOTUNE)

resize_and_rescale = tf.keras.Sequential([
  layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),
  layers.experimental.preprocessing.Rescaling(1./255),
])

data_augmentation = tf.keras.Sequential([
  layers.experimental.preprocessing.RandomFlip("horizontal_and_vertical"),
  layers.experimental.preprocessing.RandomRotation(0.2),
])

train_ds = train_ds.map(
    lambda x, y: (data_augmentation(x, training=True), y)
).prefetch(buffer_size=tf.data.AUTOTUNE)

input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)
n_classes = 6

model = models.Sequential([
    resize_and_rescale,
    layers.Conv2D(64,  kernel_size = (3,3), activation='relu', input_shape=input_shape), ##(3,3) kernal size
    layers.MaxPooling2D((2, 2)), ## pooling window size

    layers.Conv2D(64,  kernel_size = (3,3), activation='relu',  input_shape=input_shape),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64,  kernel_size = (3,3), activation='relu',  input_shape=input_shape),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64,  kernel_size = (3,3), activation='relu',  input_shape=input_shape),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64,  kernel_size = (3,3), activation='relu',  input_shape=input_shape),
    layers.MaxPooling2D((2, 2)),

    #layers.Conv2D(64,  kernel_size = (3,3), activation='relu',  input_shape=input_shape),
    #layers.MaxPooling2D((2, 2)),

    layers.Flatten(),

    layers.Dense(64, activation='relu'),
    layers.Dense(n_classes, activation='softmax'),
])

model.build(input_shape=input_shape)

model.summary()

model.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)
history = model.fit(
    train_ds,
    batch_size=BATCH_SIZE,
    validation_data=val_ds,
    verbose=1,
    epochs=50,
)

scores = model.evaluate(test_ds)

model.save('tomato_model.h5')

model = tf.keras.models.load_model('/content/tomato_model.h5')

history
history.params
history.history.keys()

type(history.history['loss'])
len(history.history['loss'])

history.history['accuracy'][:5]

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(14, 8))
plt.subplot(1, 2, 1)
epochs_range = range(1, len(acc) + 1)
plt.plot(epochs_range, acc, label='Training Accuracy', color='#e60049')
plt.plot(epochs_range, val_acc, label='Validation Accuracy', color='#00bfa0')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.show()

plt.figure(figsize=(14, 8))
plt.subplot(1, 2, 1)
epochs_range = range(1, len(loss) + 1)
plt.plot(epochs_range, loss, label='Training Loss', color='#e60049')
plt.plot(epochs_range, val_loss, label='Validation Loss', color='#00bfa0')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()

for images_batch, labels_batch in test_ds.take(1):

    first_image = images_batch[0].numpy().astype('uint8')
    first_label = labels_batch[0].numpy()

    print("First image to predict")
    plt.imshow(first_image)
    print("Actual label:", class_names[first_label])

    batch_prediction = model.predict(images_batch)
    print("Predicted label:", class_names[np.argmax(batch_prediction[0])])

def predict(model, img):
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)

    predictions = model.predict(img_array)

    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = round(100 * np.max(predictions[0]), 2)
    return predicted_class, confidence

actual_classes = []
predicted_classes = []

plt.figure(figsize=(15, 15))
for images, labels in test_ds.take(1):
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))

        predicted_class, confidence = predict(model, images[i].numpy())
        actual_class = class_names[labels[i]]
        actual_classes.append(actual_class)
        predicted_classes.append(predicted_class)

        plt.title(f"Actual: {actual_class},\n Predicted: {predicted_class}.\n Confidence: {confidence}%")

        plt.axis("off")

print("Actual Classes:", actual_classes)
print("Predicted Classes:", predicted_classes)

Y_true = []
Y_pred = []

for j in range(len(test_ds)):
    for images, labels in test_ds.take(j):
        for i in range(len(labels)):

            predicted_class, confidence = predict(model, images[i].numpy())
            actual_class = class_names[labels[i]]
            Y_true.append(actual_class)
            Y_pred.append(predicted_class)

cm = confusion_matrix(Y_true, Y_pred)
plt.figure(figsize=(7, 7))
ax = sns.heatmap(cm, cmap=plt.cm.Blues, annot=True, square=True, xticklabels=class_names, yticklabels=class_names)
ax.set_ylabel('Actual', fontsize=15)
ax.set_xlabel('Predicted', fontsize=15)

im_file = urlopen("https://i.ibb.co/GJxfzx2/Late-blight-1318.jpg")
image_file = Image.open(im_file)
plt.figure(figsize=(15, 15))

# Define 'i' before using it
i = 0  # You need to set an appropriate value for 'i' based on your requirements

ax = plt.subplot(3, 3, i + 1)
plt.imshow(image_file)
predicted_class, confidence = predict(model, np.array(image_file))
plt.title(f"Predicted: {predicted_class}.\n Confidence: {confidence}%")
plt.axis("off")
plt.show()

im_file = urlopen("https://i.ibb.co/VB9TSMX/Healthy-1412.jpg")
image_file = Image.open(im_file)
plt.figure(figsize=(15, 15))

# Define 'i' before using it
i = 0  # You need to set an appropriate value for 'i' based on your requirements

ax = plt.subplot(3, 3, i + 1)
plt.imshow(image_file)
predicted_class, confidence = predict(model, np.array(image_file))
plt.title(f"Predicted: {predicted_class}.\n Confidence: {confidence}%")
plt.axis("off")
plt.show()

im_file = urlopen("https://i.ibb.co/5W3mtnj/Mosaic-virus-1242.jpg")
image_file = Image.open(im_file)
plt.figure(figsize=(15, 15))

# Define 'i' before using it
i = 0  # You need to set an appropriate value for 'i' based on your requirements

ax = plt.subplot(3, 3, i + 1)
plt.imshow(image_file)
predicted_class, confidence = predict(model, np.array(image_file))
plt.title(f"Predicted: {predicted_class}.\n Confidence: {confidence}%")
plt.axis("off")
plt.show()

im_file = urlopen("https://i.ibb.co/x8nQ2Pg/Mosaic-virus-496.jpg")
image_file = Image.open(im_file)
plt.figure(figsize=(15, 15))

# Define 'i' before using it
i = 0  # You need to set an appropriate value for 'i' based on your requirements

ax = plt.subplot(3, 3, i + 1)
plt.imshow(image_file)
predicted_class, confidence = predict(model, np.array(image_file))
plt.title(f"Predicted: {predicted_class}.\n Confidence: {confidence}%")
plt.axis("off")
plt.show()